# -*- coding: utf-8 -*-
"""project_gan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1trUbSMts7L1k3fBUt7nHe97LRyzhatL0
"""

import os
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import warnings

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import load_img,array_to_img
from tensorflow.keras.models import Sequential,Model
from tensorflow.keras import layers
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import BinaryCrossentropy

!pip install opendatasets

import opendatasets as od
od.download("https://www.kaggle.com/datasets/soumikrakshit/anime-faces")

import os

folder_path = "/content/anime-faces/data/data"
valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp')

# Filter only valid image files
image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(valid_extensions)]

print(f"Total images: {len(image_files)}")
print("Sample images:", image_files[:10])

"""**Visulaize the dataset**"""

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import os

# Folder path
folder_path = "/content/anime-faces/data/data"
valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp')

# Filter and sort image files (first 50 valid ones)
image_files = sorted([f for f in os.listdir(folder_path) if f.lower().endswith(valid_extensions)])[:50]

# Plot settings
plt.figure(figsize=(20, 10))  # 5 rows Ã— 10 columns = 50

for i, img_name in enumerate(image_files):
    img_path = os.path.join(folder_path, img_name)
    try:
        img = mpimg.imread(img_path)
        plt.subplot(5, 10, i + 1)
        plt.imshow(img)
        plt.axis("off")
    except Exception as e:
        print(f"Error loading {img_name}: {e}")

plt.suptitle("First 50 Anime Faces", fontsize=20)
plt.tight_layout()
plt.show()

"""**Preprocess Images**"""

import os
import numpy as np
from tqdm import tqdm
from tensorflow.keras.preprocessing.image import load_img, img_to_array

# Define folder path
folder_path = "/content/anime-faces/data/data"
valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp')

# Get and filter image filenames
image_files = sorted([f for f in os.listdir(folder_path) if f.lower().endswith(valid_extensions)])

# Create list of full image paths
image_paths = [os.path.join(folder_path, img_name) for img_name in image_files]

# Set target image size (common for anime GANs: 64x64 or 128x128)
img_size = (64, 64)

# Load all images, resize, normalize to [-1, 1]
train_images = []
for path in tqdm(image_paths, desc="Loading and processing images"):
    try:
        img = load_img(path, target_size=img_size)
        img_array = img_to_array(img)
        img_array = (img_array / 127.5) - 1.0  # Normalize to [-1, 1]
        train_images.append(img_array)
    except Exception as e:
        print(f"Skipping {path}: {e}")

# Convert to final NumPy array
train_images = np.array(train_images, dtype=np.float32)

# Check shape
print("Shape of train_images:", train_images.shape)

train_images.shape

train_images[0]

"""**Create generator and discriminator**"""

from tensorflow.keras import initializers

# Latent vector dimension (size of random noise input to Generator)
LATENT_DIM = 100

# Weight initializer as per DCGAN paper: N(0, 0.02)
WEIGHT_INIT = initializers.RandomNormal(mean=0.0, stddev=0.02)

# Number of channels (3 for RGB anime images)
CHANNELS = 3

"""**Generator Model**"""

from tensorflow.keras import layers, models

def build_generator(latent_dim, channels=3):
    model = models.Sequential(name="Generator")

    model.add(layers.Dense(8 * 8 * 256, use_bias=False, input_shape=(latent_dim,),
                           kernel_initializer=WEIGHT_INIT))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())
    model.add(layers.Reshape((8, 8, 256)))  # Now 8x8x256

    model.add(layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding='same',
                                     use_bias=False, kernel_initializer=WEIGHT_INIT))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())  # Now 16x16x128

    model.add(layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding='same',
                                     use_bias=False, kernel_initializer=WEIGHT_INIT))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())  # Now 32x32x64

    model.add(layers.Conv2DTranspose(channels, kernel_size=4, strides=2, padding='same',
                                     use_bias=False, activation='tanh',
                                     kernel_initializer=WEIGHT_INIT))  # Final 64x64x3

    return model

"""**Discriminator model**"""

def build_discriminator(input_shape=(64, 64, 3)):
    model = models.Sequential(name="Discriminator")

    model.add(layers.Conv2D(64, kernel_size=4, strides=2, padding='same',
                            input_shape=input_shape, kernel_initializer=WEIGHT_INIT))
    model.add(layers.LeakyReLU(0.2))

    model.add(layers.Conv2D(128, kernel_size=4, strides=2, padding='same',
                            kernel_initializer=WEIGHT_INIT))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU(0.2))

    model.add(layers.Conv2D(256, kernel_size=4, strides=2, padding='same',
                            kernel_initializer=WEIGHT_INIT))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU(0.2))

    model.add(layers.Flatten())
    model.add(layers.Dense(1, activation='sigmoid', kernel_initializer=WEIGHT_INIT))

    return model

"""**Create DCGAN**"""

import tensorflow as tf

class DCGAN(keras.Model):
    def __init__(self, generator, discriminator, latent_dim):
        super(DCGAN, self).__init__()
        self.generator = generator
        self.discriminator = discriminator
        self.latent_dim = latent_dim

    def compile(self, g_optimizer, d_optimizer, loss_fn):
        super(DCGAN, self).compile()
        self.g_optimizer = g_optimizer
        self.d_optimizer = d_optimizer
        self.loss_fn = loss_fn

        self.d_loss_metric = keras.metrics.Mean(name="d_loss")
        self.g_loss_metric = keras.metrics.Mean(name="g_loss")

    @property
    def metrics(self):
        return [self.d_loss_metric, self.g_loss_metric]

    def train_step(self, real_images):
        batch_size = tf.shape(real_images)[0]

        # Generate random noise
        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))

        # Generate fake images
        generated_images = self.generator(random_latent_vectors)

        # Combine real and fake images
        combined_images = tf.concat([real_images, generated_images], axis=0)

        # Assign labels: 1s for real, 0s for fake
        labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)

        # Add noise to labels
        labels += 0.05 * tf.random.uniform(tf.shape(labels))

        # Train Discriminator
        with tf.GradientTape() as tape:
            predictions = self.discriminator(combined_images)
            d_loss = self.loss_fn(labels, predictions)

        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)
        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))

        # Train Generator
        misleading_labels = tf.ones((batch_size, 1))

        with tf.GradientTape() as tape:
            fake_images = self.generator(random_latent_vectors)
            predictions = self.discriminator(fake_images)
            g_loss = self.loss_fn(misleading_labels, predictions)

        grads = tape.gradient(g_loss, self.generator.trainable_weights)
        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))

        # Track losses
        self.d_loss_metric.update_state(d_loss)
        self.g_loss_metric.update_state(g_loss)

        return {"d_loss": self.d_loss_metric.result(), "g_loss": self.g_loss_metric.result()}

import matplotlib.pyplot as plt
import numpy as np
import os

class DCGANMonitor(keras.callbacks.Callback):
    def __init__(self, num_images=16, latent_dim=100, save_path="generated_images"):
        self.num_images = num_images
        self.latent_dim = latent_dim
        self.save_path = save_path
        os.makedirs(save_path, exist_ok=True)

        # Fixed seed for consistent output
        self.seed = tf.random.normal([num_images, latent_dim])

    def on_epoch_end(self, epoch, logs=None):
        generated_images = self.model.generator(self.seed)
        generated_images = (generated_images * 127.5) + 127.5  # Rescale to [0,255]
        generated_images = tf.cast(generated_images, tf.uint8)

        # Plot
        fig = plt.figure(figsize=(4, 4))
        for i in range(self.num_images):
            plt.subplot(4, 4, i + 1)
            img = generated_images[i].numpy()
            plt.imshow(img)
            plt.axis("off")

        plt.tight_layout()
        save_name = os.path.join(self.save_path, f"epoch_{epoch+1:03d}.png")
        plt.savefig(save_name)
        plt.close()

generator = build_generator(LATENT_DIM, channels=CHANNELS)
discriminator = build_discriminator(input_shape=(64, 64, CHANNELS))

dcgan = DCGAN(generator=generator, discriminator=discriminator, latent_dim=LATENT_DIM)

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import BinaryCrossentropy

# Optimizers (LR = 0.0002, beta_1 = 0.5 as per DCGAN paper)
g_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)
d_optimizer = Adam(learning_rate=0.0002, beta_1=0.5)

loss_fn = BinaryCrossentropy()

dcgan.compile(g_optimizer=g_optimizer, d_optimizer=d_optimizer, loss_fn=loss_fn)

monitor_callback = DCGANMonitor(num_images=16, latent_dim=LATENT_DIM, save_path="generated_faces")

BUFFER_SIZE = train_images.shape[0]
BATCH_SIZE = 128

dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)

EPOCHS = 100  # You can increase this if needed

dcgan.fit(dataset, epochs=EPOCHS, callbacks=[monitor_callback])

import numpy as np
import matplotlib.pyplot as plt

# Number of images to generate
num_images = 1

# Sample random noise vectors
random_latent_vectors = np.random.normal(size=(num_images, LATENT_DIM))

# Generate fake images
generated_images = generator.predict(random_latent_vectors)

# Rescale pixel values from [-1, 1] to [0, 1]
generated_images = (generated_images + 1) / 2.0

# Plot generated images
plt.figure(figsize=(3, 3))
for i in range(num_images):
    plt.subplot(1, num_images, i + 1)
    plt.imshow(generated_images[i])
    plt.axis('off')
plt.show()

from zipfile import ZipFile
import shutil

# Zip the folder
shutil.make_archive('generated_faces', 'zip', 'generated_faces')

# Now download using google.colab files module
from google.colab import files
files.download('generated_faces.zip')